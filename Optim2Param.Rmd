Libraries and source helper functions

```{r}
library(tidyr)
library(purrr)
library(readr)
library(ggplot2)
library(langcog)
library(boot)
library(lazyeval)
library(dplyr)
library(wordbankr)
library(directlabels)
library(scales)
library(stringr)
source("all_helper.r")
data<- read.csv(paste(getwd(), "/out_files/English_assoc_PAC.csv", sep = ""), as.is = T) %>% 
  filter(learned==1) %>%
  rowwise() %>%
  mutate(value2=str_count(Speak(lang="English (American)",word=definition)))
data
month<- data$month
assoc<- data$value
len<- data$value2

lm_PAC<- lm(assoc ~ month +len)
summary(lm_PAC)

# ggplot(lm_PAC , aes(x=month, y=assoc))+
#   geom_point(alpha=1/2, position = position_jitter(h=0))+
#   scale_y_continuous(breaks = seq(0,20, by=1))+
#   scale_x_continuous(breaks = seq(16,30, by=1))+
#   geom_smooth(method = "lm", se = FALSE) +
#   ggtitle(label = "PAC degree; T<=2")

```

```{r}
make_aoa_dataframe(lang = "English (American)")
```

```{r}
source("all_helper.r")
import_all_library()

parent_freq<- read.csv(paste(getwd(),"/in_files/parent_freq.csv", sep = ""), as.is = T)
PAC_frame<- make_aoa_dataframe(lang = "English (American)") %>%
  trim_all_definition() %>%
  filter(definition %in% parent_freq$definition) %>%
  trim_all_unilemma()

lemmalist<- PAC_frame %>% filter(month==16) %>% select(item, uni_lemma)
lemmalist
assoc_pairs<- make_assoc_pairs(lemma_list = lemmalist)
assoc_PAC<- PAC_generator(vocab_month = PAC_frame, pairs = assoc_pairs) %>%
  left_join(parent_freq) %>%
  rename(value2=freq) %>%
  mutate(value2=as.numeric(value2))

write_out_csv(var = assoc_PAC, lang = "English (American)", type = "assoc_PAC")
data<- read.csv(paste(getwd(),"/out_files/English (American)_assoc_PAC.csv", sep = ""), as.is = T)
data
```
```{r}
#data<- assoc_PAC
PAC_frame
month<- data$month
assoc<- data$value
freq<- data$value2

lm_PAC<- lm(assoc ~ freq)
summary(lm_PAC)
```


Optimization 
```{r}
# This is the loglikelihood function we're trying to MINIMIZE
loglike <- function(betas){
beta<-betas[1]
beta2<- betas[2]
#beta=0
#beta2=0
# calculate numerator
  learned_words<- data %>%
    filter(learned==1) %>%
    mutate(numerator=exp(value*beta+value2*beta2)) %>%
    select(month, numerator)
  
# calculate denumerator
  all_words<- data %>%
    group_by(month) %>%
    summarise(denominator=sum(exp(value*beta+value2*beta2))) %>%
    select(month, denominator)
  
# calculate the return value
  ret<- learned_words %>%
    left_join(all_words) %>%
    summarise(nLLK=sum(log(numerator/denominator)))

  return(-ret$nLLK)
  
}
```

```{r, message=FALSE, warning=FALSE}
#data<- read.csv(paste(getwd(),"/out_files/English (American)_assoc_PAC.csv", sep = ""), as.is = T)
  
# data<- read.csv(paste(getwd(),"/out_files/English (American)_assoc_PAC_wotrim.csv", sep = ""), as.is = T) %>%
#   mutate(value=str_count(definition))
# data
optim(c(0,0), loglike2)
# error message: Error in statistic(data, original, ...) : 
```

```{r}
# this helps us to get the parameter from optim()
optim_param <- function(data, indices) {

  data_replicate = data[indices, ]

loglike <- function(beta){
  
# calculate numerator
  learned_words<- data_replicate %>%
    filter(learned==1) %>%
    mutate(numerator=exp(value*beta)) %>%
    select(month, numerator)
  
# calculate denumerator
  all_words<- data_replicate %>%
    group_by(month) %>%
    summarise(denominator=sum(exp(value*beta))) %>%
    select(month, denominator)
  
# calculate the return value
  ret<- learned_words %>%
    left_join(all_words) %>%
    summarise(nLLK=sum(log(numerator/denominator)))

  return(-ret$nLLK)
  
}


  optim_stat <- optim(0, loglike(beta))

  return(optim_stat$par)
}

``` 

```{r}
optim(0, loglike)
# error message: Error in statistic(data, original, ...) : 
```


```{r}
dat<- data.frame(model =factor(c("Random", "Assoc_PAC", "Freq", "Freq+Assoc_PAC")),
                 nLLK = c(1217.259,1209.292,1185.721, 1183.899))
dat
ggplot(data=dat, aes(x=reorder(model,-nLLK), y=nLLK))+labs(x="Models")+geom_bar(stat="identity")+ coord_cartesian(ylim=c(1180, 1220)) +ggtitle(label = "Models of Non-Polysemous Nouns")
```

```{r}
dat<- data.frame(model =factor(c("Random", "Assoc_PAC", "Freq", "Freq+Assoc_PAC")),
                 nLLK = c(968.8504,962.4004,968.8386,962.4154))
dat
ggplot(data=dat, aes(x=reorder(model,-nLLK), y=nLLK))+labs(x="Models")+geom_bar(stat="identity")+ coord_cartesian(ylim=c(960, 970)) +ggtitle(label = "Models of All Nouns (including Polysemy)")

```


